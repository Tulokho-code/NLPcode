{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dự án Dịch Máy: Seq2Seq với Attention (EN → FR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Cài đặt và Tải Dữ Liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHJoeiXs0Gdc",
        "outputId": "1840471c-438d-490d-f8d5-2de20edbdce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting spacy==3.8.2\n",
            "  Downloading spacy-3.8.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting torchtext==0.18.0\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (0.4.3)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (25.0)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy==3.8.2)\n",
            "  Downloading langcodes-3.5.1-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.8.2) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.9.0+cu126)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.2) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.2) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.2) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.2) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.0->spacy==3.8.2) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.0->spacy==3.8.2) (0.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.6.1)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy==3.8.2) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy==3.8.2) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy==3.8.2) (13.9.4)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy==3.8.2) (0.20.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy==3.8.2) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy==3.8.2) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy==3.8.2) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.8.2) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.8.2) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy==3.8.2) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3.0->torchtext==0.18.0) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.8.2) (0.1.2)\n",
            "Downloading spacy-3.8.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.8/31.8 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langcodes-3.5.1-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.1/183.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, langcodes, colorama, sacrebleu, torchtext, spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.8.11\n",
            "    Uninstalling spacy-3.8.11:\n",
            "      Successfully uninstalled spacy-3.8.11\n",
            "Successfully installed colorama-0.4.6 langcodes-3.5.1 portalocker-3.2.0 sacrebleu-2.5.1 spacy-3.8.2 torchtext-0.18.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "f82e5d021dad41f091dabb351ce6e123",
              "pip_warning": {
                "packages": [
                  "spacy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'spacy.pipeline.factories'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2446664588.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Load mô hình spaCy cho tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mspacy_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mspacy_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fr_core_news_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m     51\u001b[0m     return util.load_model(\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mpipes\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mwon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mrun\u001b[0m \u001b[0munless\u001b[0m \u001b[0myou\u001b[0m \u001b[0mexplicitly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0menable\u001b[0m \u001b[0mthem\u001b[0m \u001b[0mby\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m     \u001b[0menable\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mAll\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mpipes\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdisabled\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mand\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0menabled\u001b[0m \u001b[0musing\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pipe\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0mexclude\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mExcluded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0mauto_fill\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m ) -> \"Language\":\n\u001b[0m\u001b[1;32m    561\u001b[0m     \"\"\"Create an nlp object from a config. Expects the full config file including\n\u001b[1;32m    562\u001b[0m     \u001b[0ma\u001b[0m \u001b[0msection\u001b[0m \u001b[0;34m\"nlp\"\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msettings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/en_core_web_sm/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_package_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \"\"\"Get the version of an installed package. Typically used to get model\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    596\u001b[0m     )\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m def get_sourced_components(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_config\u001b[0;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"not a valid section reference: {name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"loc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"msg\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mConfigValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[1;32m   1855\u001b[0m         \u001b[0;31m# inside stuff like the spacy train function. If we loaded them here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m         \u001b[0;31m# then we would load them twice at runtime: once when we make from config,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m         \u001b[0;31m# and then again when we load from disk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1858\u001b[0m         nlp = lang_cls(\n\u001b[1;32m   1859\u001b[0m             \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab, max_length, meta, create_tokenizer, create_vectors, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDefault\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mDOCS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;31m#init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# We're only calling this to import all factories provided via entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy.pipeline.factories'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cài đặt thư viện (nếu chạy trong Colab hoặc môi trường mới)\n",
        "!pip install spacy==3.8.2 torchtext==0.18.0 sacrebleu\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm\n",
        "\n",
        "# Import các thư viện cần thiết\n",
        "import random\n",
        "import spacy\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
        "from collections import Counter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import sacrebleu\n",
        "from sacrebleu import sentence_bleu\n",
        "\n",
        "# Load mô hình spaCy cho tokenize\n",
        "spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "# Hàm tokenize cho tiếng Anh\n",
        "def tokenize_en(text):\n",
        "    return [tok.text.lower() for tok in spacy_en.tokenizer(text)]  # Tokenize và chuyển về chữ thường\n",
        "\n",
        "# Hàm tokenize cho tiếng Pháp\n",
        "def tokenize_fr(text):\n",
        "    return [tok.text.lower() for tok in spacy_fr.tokenizer(text)]  # Tokenize và chuyển về chữ thường\n",
        "\n",
        "# Tải dữ liệu Multi30K từ GitHub\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.en.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.fr.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.en.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.fr.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/test_2016_flickr.en.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/test_2016_flickr.fr.gz\n",
        "\n",
        "# Giải nén file\n",
        "!gunzip -f *.gz\n",
        "\n",
        "# Hàm load lines từ file\n",
        "def load_lines(file):\n",
        "    with open(file, encoding='utf-8') as f:\n",
        "        return [line.strip() for line in f]  # Đọc từng dòng và loại bỏ khoảng trắng thừa\n",
        "\n",
        "# Load dữ liệu train, val, test\n",
        "train_en = load_lines(\"train.en\")\n",
        "train_fr = load_lines(\"train.fr\")\n",
        "val_en   = load_lines(\"val.en\")\n",
        "val_fr   = load_lines(\"val.fr\")\n",
        "test_en  = load_lines(\"test_2016_flickr.en\")\n",
        "test_fr  = load_lines(\"test_2016_flickr.fr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Xây Dựng Từ Vựng (Vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXNX-WdM0Mg2",
        "outputId": "11943ad1-69d9-4046-8959-aff0a243311e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EN vocab: 9,797 | FR vocab: 10,000\n"
          ]
        }
      ],
      "source": [
        "# Hàm xây vocab từ list sentences\n",
        "def build_vocab(sentences, tokenizer, max_size=10000):\n",
        "    counter = Counter()  # Đếm tần suất từ\n",
        "    for s in sentences:\n",
        "        counter.update(tokenizer(s))  # Cập nhật counter từ tokens của mỗi câu\n",
        "    vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}  # Các token đặc biệt\n",
        "    for word, freq in counter.most_common(max_size - 4):  # Lấy top từ phổ biến\n",
        "        vocab[word] = len(vocab)  # Gán index tăng dần\n",
        "    return vocab\n",
        "\n",
        "# Xây vocab cho nguồn (EN) và đích (FR)\n",
        "SRC_vocab = build_vocab(train_en, tokenize_en)\n",
        "TRG_vocab = build_vocab(train_fr, tokenize_fr)\n",
        "\n",
        "print(f\"EN vocab: {len(SRC_vocab):,} | FR vocab: {len(TRG_vocab):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset và Collate Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class Dataset cho dữ liệu dịch máy\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_lines, trg_lines):\n",
        "        self.src_lines = src_lines  # List câu nguồn\n",
        "        self.trg_lines = trg_lines  # List câu đích\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_lines)  # Độ dài dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize và thêm <sos>/<eos> cho nguồn\n",
        "        src = [\"<sos>\"] + tokenize_en(self.src_lines[idx]) + [\"<eos>\"]\n",
        "        # Tokenize và thêm <sos>/<eos> cho đích\n",
        "        trg = [\"<sos>\"] + tokenize_fr(self.trg_lines[idx]) + [\"<eos>\"]\n",
        "        # Chuyển token thành ID (sử dụng <unk> nếu không có trong vocab)\n",
        "        src_ids = [SRC_vocab.get(t, SRC_vocab[\"<unk>\"]) for t in src]\n",
        "        trg_ids = [TRG_vocab.get(t, TRG_vocab[\"<unk>\"]) for t in trg]\n",
        "        return torch.tensor(src_ids), torch.tensor(trg_ids)  # Trả về tensor nguồn và đích\n",
        "\n",
        "# Collate function để batch data (padding và packing)\n",
        "def collate_fn(batch):\n",
        "    srcs, trgs = zip(*batch)  # Tách nguồn và đích từ batch\n",
        "    src_lens = [len(s) for s in srcs]  # Độ dài nguồn\n",
        "    trg_lens = [len(t) for t in trgs]  # Độ dài đích\n",
        "    # Padding nguồn với <pad>\n",
        "    srcs_pad = pad_sequence(srcs, batch_first=True, padding_value=SRC_vocab[\"<pad>\"])\n",
        "    # Padding đích với <pad>\n",
        "    trgs_pad = pad_sequence(trgs, batch_first=True, padding_value=TRG_vocab[\"<pad>\"])\n",
        "    return srcs_pad, trgs_pad, src_lens, trg_lens  # Trả về padded tensors và lengths\n",
        "\n",
        "# Tạo dataset\n",
        "train_dataset = TranslationDataset(train_en, train_fr)\n",
        "val_dataset   = TranslationDataset(val_en, val_fr)\n",
        "test_dataset  = TranslationDataset(test_en, test_fr)\n",
        "\n",
        "# Tạo DataLoader (batch size 128, shuffle cho train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=128, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Mô Hình (Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Device (GPU nếu có)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Encoder: LSTM với embedding\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)  # Embedding layer\n",
        "        self.dropout = nn.Dropout(dropout)  # Dropout để tránh overfitting\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, batch_first=True, bidirectional=False)  # LSTM đơn hướng\n",
        "\n",
        "    def forward(self, src, src_len):\n",
        "        embedded = self.dropout(self.embedding(src))  # (B, L, emb_dim)\n",
        "        packed = pack_padded_sequence(embedded, src_len, batch_first=True, enforce_sorted=False)  # Pack để bỏ padding\n",
        "        packed_out, (h, c) = self.lstm(packed)  # LSTM forward\n",
        "        outputs, _ = pad_packed_sequence(packed_out, batch_first=True)  # Unpack outputs (B, L, hid_dim)\n",
        "        h = h.view(1, h.size(1), -1)  # Reshape hidden (1, B, hid_dim)\n",
        "        c = c.view(1, c.size(1), -1)  # Reshape cell (1, B, hid_dim)\n",
        "        return outputs, h, c  # Outputs cho attention, h/c cho decoder init\n",
        "\n",
        "# Attention: Additive attention (Bahdanau)\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hid_dim + hid_dim, hid_dim)  # Linear để tính energy\n",
        "        self.v = nn.Parameter(torch.rand(hid_dim))  # Vector v cho attention score\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        hidden = hidden.permute(1, 0, 2)  # (B, 1, hid_dim)\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "        hidden = hidden.repeat(1, src_len, 1)  # Repeat hidden theo src_len (B, src_len, hid_dim)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # (B, src_len, hid_dim)\n",
        "        energy = energy.permute(0, 2, 1)  # (B, hid_dim, src_len)\n",
        "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # (B, 1, hid_dim)\n",
        "        attn_scores = torch.bmm(v, energy).squeeze(1)  # (B, src_len)\n",
        "        return F.softmax(attn_scores, dim=1)  # Softmax để có weights\n",
        "\n",
        "# Decoder: LSTM với attention\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(emb_dim + hid_dim, hid_dim, batch_first=True)  # Input: emb + context\n",
        "        self.fc_out = nn.Linear(hid_dim, vocab_size)  # Output layer\n",
        "        self.attention = Attention(hid_dim)  # Attention module\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(1)  # (B) → (B, 1)\n",
        "        embedded = self.dropout(self.embedding(input))  # (B, 1, emb_dim)\n",
        "        attn_weights = self.attention(hidden, encoder_outputs)  # (B, src_len)\n",
        "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)  # (B, 1, hid_dim)\n",
        "        lstm_input = torch.cat((embedded, context), dim=2)  # (B, 1, emb_dim + hid_dim)\n",
        "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))  # LSTM forward\n",
        "        output = self.fc_out(output.squeeze(1))  # (B, vocab_size)\n",
        "        return output, hidden, cell\n",
        "\n",
        "# Seq2Seq: Kết hợp encoder và decoder\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, src_len, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        trg_vocab_size = self.decoder.fc_out.out_features\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)  # Init outputs\n",
        "        encoder_outputs, hidden, cell = self.encoder(src, src_len)  # Encode\n",
        "        input = trg[:, 0]  # Bắt đầu từ <sos>\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)  # Decode\n",
        "            outputs[:, t, :] = output  # Lưu output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio  # Teacher forcing\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[:, t] if teacher_force else top1  # Input tiếp theo\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Huấn Luyện (Training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Khởi tạo model\n",
        "INPUT_DIM = len(SRC_vocab)\n",
        "OUTPUT_DIM = len(TRG_vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DROPOUT)\n",
        "attn_model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "# Optimizer và loss\n",
        "optimizer = optim.Adam(attn_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_vocab[\"<pad>\"])  # Bỏ qua padding\n",
        "\n",
        "# Hàm train một epoch\n",
        "def train(model, iterator, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for src, trg, src_len, _ in iterator:\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, src_len)  # Forward\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)  # Bỏ <sos>, flatten\n",
        "        trg = trg[:, 1:].reshape(-1)  # Bỏ <sos>, flatten\n",
        "        loss = criterion(output, trg)  # Tính loss\n",
        "        loss.backward()  # Backward\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  # Gradient clipping\n",
        "        optimizer.step()  # Update weights\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)  # Average loss\n",
        "\n",
        "# Hàm eval một epoch\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg, src_len, _ in iterator:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            output = model(src, trg, src_len, 0)  # No teacher forcing\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "# Vòng lặp huấn luyện (ví dụ 10 epochs)\n",
        "N_EPOCHS = 10\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(attn_model, train_loader, optimizer, criterion)\n",
        "    val_loss = evaluate(attn_model, val_loader, criterion)\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Vẽ Biểu Đồ Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vẽ biểu đồ loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Training Loss', marker='o')\n",
        "plt.plot(val_losses, label='Validation Loss', marker='o')\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(0, len(train_losses), 2))  # Hiển thị mỗi 2 epochs\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Hàm Dịch Một Câu (Translate Sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reverse vocab cho đích (id → word)\n",
        "id2word_trg = {v: k for k, v in TRG_vocab.items()}\n",
        "\n",
        "# Hàm dịch một câu EN → FR\n",
        "def translate(sentence: str, max_len: int = 50) -> str:\n",
        "    attn_model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Tokenize nguồn và thêm <sos>/<eos>\n",
        "        src_tokens = [\"<sos>\"] + tokenize_en(sentence) + [\"<eos>\"]\n",
        "        src_ids = [SRC_vocab.get(t, SRC_vocab[\"<unk>\"]) for t in src_tokens]\n",
        "        src_tensor = torch.LongTensor(src_ids).unsqueeze(0).to(device)  # (1, src_len)\n",
        "        src_len = [len(src_ids)]\n",
        "        \n",
        "        # Encode\n",
        "        encoder_outputs, hidden, cell = attn_model.encoder(src_tensor, src_len)\n",
        "        \n",
        "        # Decode từ <sos>\n",
        "        input_token = torch.tensor([TRG_vocab[\"<sos>\"]]).to(device)\n",
        "        translated_tokens = []\n",
        "        for _ in range(max_len):\n",
        "            output, hidden, cell = attn_model.decoder(input_token, hidden, cell, encoder_outputs)\n",
        "            pred_token = output.argmax(1).item()\n",
        "            if pred_token == TRG_vocab[\"<eos>\"]:\n",
        "                break\n",
        "            translated_tokens.append(id2word_trg[pred_token])  # Thêm token dự đoán\n",
        "            input_token = torch.tensor([pred_token]).to(device)  # Input tiếp theo\n",
        "        return \" \".join(translated_tokens)  # Trả về câu dịch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Tính BLEU Score Trên Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Thu thập hypotheses và references\n",
        "hypotheses = []  # List câu dịch (str)\n",
        "references_single = []  # List references (str)\n",
        "\n",
        "attn_model.eval()\n",
        "with torch.no_grad():\n",
        "    for src, trg, src_len, trg_len in test_loader:\n",
        "        src = src.to(device)\n",
        "        for i in range(src.size(0)):\n",
        "            src_single = src[i:i+1]  # (1, src_len)\n",
        "            src_len_single = [src_len[i]]\n",
        "            hyp_tokens = translate_sentence(attn_model, src_single, src_len_single)  # Dịch\n",
        "            hypotheses.append(\" \".join(hyp_tokens))  # Thêm hypothesis\n",
        "            \n",
        "            # Xử lý reference: bỏ <sos>/<eos>\n",
        "            trg_ids = trg[i].tolist()\n",
        "            eos_idx = trg_ids.index(TRG_vocab[\"<eos>\"]) if TRG_vocab[\"<eos>\"] in trg_ids else len(trg_ids)\n",
        "            ref_ids = trg_ids[1:eos_idx]\n",
        "            ref_tokens = [id2word_trg[j] for j in ref_ids]\n",
        "            references_single.append(\" \".join(ref_tokens))  # Thêm reference\n",
        "\n",
        "# Tính average BLEU\n",
        "sentence_scores = []\n",
        "for hyp, ref in zip(hypotheses, references_single):\n",
        "    score = sentence_bleu(hyp, [ref])  # Tính BLEU cho từng câu\n",
        "    sentence_scores.append(score.score)\n",
        "\n",
        "avg_bleu = sum(sentence_scores) / len(sentence_scores)\n",
        "print(f\"Test BLEU score: {avg_bleu:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test Với Các Câu Ví Dụ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Các câu ví dụ\n",
        "example_sentences = [\n",
        "    \"A man is playing a guitar.\",\n",
        "    \"Two dogs are running in the park.\",\n",
        "    \"A woman is riding a horse.\",\n",
        "    \"A group of people are dancing.\"\n",
        "]\n",
        "\n",
        "print(\"=== Kết quả dịch ===\\n\")\n",
        "for en_sent in example_sentences:\n",
        "    fr_sent = translate(en_sent)\n",
        "    print(f\"EN: {en_sent}\")\n",
        "    print(f\"FR: {fr_sent}\")\n",
        "    print(\"-\" * 50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Welcome To Colab",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
